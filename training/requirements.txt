# Unsloth Training Requirements for Gemma 3 Fine-tuning
# Updated for 2025 - Supports Gemma 3 with optimized memory usage

# Core Unsloth and dependencies
unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git
torch>=2.1.0
transformers>=4.36.0
datasets>=2.14.0
trl>=0.7.4
accelerate>=0.24.0

# Quantization and optimization
bitsandbytes>=0.41.3
peft>=0.6.0

# Data processing
pandas>=1.5.0
numpy>=1.24.0
Pillow>=9.0.0

# Development and utilities
jupyter>=1.0.0
ipywidgets>=8.0.0
matplotlib>=3.7.0
seaborn>=0.12.0

# Optional: For advanced training monitoring
wandb>=0.15.0
tensorboard>=2.13.0

# Memory profiling (useful for VRAM optimization)
psutil>=5.9.0
GPUtil>=1.4.0